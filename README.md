# Data obfuscation methods for privacy-preserving machine learning

## HE-ML

Tests of various Homomorphic Encryption (HE) Machine Learning (ML) frameworks.
See the markdown files for individual frameworks.

### Tested
* [EncryptedStats -- Homomorphic Encryption in R](https://github.com/kalleknast/HE-ML/blob/master/EncryptedStats.md)

    [EncryptedStats webpage](http://www.louisaslett.com/EncryptedStats/)
* [HEML -- Logistic Regression based on Approximate HE](https://github.com/kalleknast/HE-ML/blob/master/HEML.md)

    [Paper](https://eprint.iacr.org/2018/254)

    [github repo](https://github.com/kimandrik/HEML)
    
### Not yet tested
* [NuCyphe's nuFHE](https://github.com/nucypher/nuFHE)

### Conclusion
Not viable

## Clear-text data obfuscation

### Geometric Data Perturbation ([GDP](https://cecs.wright.edu/~keke.chen/))

[Paper](https://www.researchgate.net/publication/220283635_Geometric_data_perturbation_for_privacy_preserving_outsourced_data_mining)

[Code and test](https://github.com/kalleknast/GDP)

